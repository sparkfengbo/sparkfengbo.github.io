<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://sparkfengbo.github.io</id>
    <title>FengBo`s Blog</title>
    <updated>2020-10-12T12:12:46.210Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://sparkfengbo.github.io"/>
    <link rel="self" href="https://sparkfengbo.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://sparkfengbo.github.io/images/avatar.png</logo>
    <icon>https://sparkfengbo.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, FengBo`s Blog</rights>
    <entry>
        <title type="html"><![CDATA[About]]></title>
        <id>https://sparkfengbo.github.io/post/about/</id>
        <link href="https://sparkfengbo.github.io/post/about/">
        </link>
        <updated>2020-10-12T12:10:28.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>欢迎来到我的小站呀，很高兴遇见你！🤝</p>
</blockquote>
<h2 id="关于本站">🏠 关于本站</h2>
<blockquote>
<p>平日学习记录，希望能够帮到你</p>
</blockquote>
<h2 id="博主是谁">👨‍💻 博主是谁</h2>
<blockquote>
<p>普通程序员，先后就职于百度、字节跳动</p>
</blockquote>
<h2 id="联系我呀">📬 联系我呀</h2>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linux IO模型简介和IO多路复用]]></title>
        <id>https://sparkfengbo.github.io/post/czxt-linux-io-mo-xing-jian-jie-he-io-duo-lu-fu-yong/</id>
        <link href="https://sparkfengbo.github.io/post/czxt-linux-io-mo-xing-jian-jie-he-io-duo-lu-fu-yong/">
        </link>
        <updated>2020-10-12T10:33:34.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li>
<p><a href="https://www.jianshu.com/p/f8bc7199bb8e">Linux IO模型：阻塞/非阻塞/IO复用 同步/异步 Select/Epoll/AIO</a></p>
</li>
<li>
<p><a href="https://mp.weixin.qq.com/s?__biz=Mzg3MjA4MTExMw==&amp;mid=2247484746&amp;idx=1&amp;sn=c0a7f9129d780786cabfcac0a8aa6bb7&amp;source=41#wechat_redirect">漫话：如何给女朋友解释什么是Linux的五种IO模型？</a></p>
</li>
<li>
<p><a href="https://www.jianshu.com/p/dfd940e7fca2">聊聊IO多路复用之select、poll、epoll详解</a></p>
</li>
<li>
<p><a href="https://ring0.me/2014/11/sync-async-blocked/">大话同步/异步、阻塞/非阻塞</a></p>
</li>
<li>
<p><a href="https://blog.csdn.net/historyasamirror/article/details/5778378">IO - 同步，异步，阻塞，非阻塞 （亡羊补牢篇）</a></p>
</li>
<li>
<p>这篇文章图是中文的  <a href="https://www.jianshu.com/p/02f76566fd90">怎样理解阻塞非阻塞与同步异步的区别？</a></p>
</li>
</ul>
<h1 id="linux-io模型">Linux IO模型</h1>
<ul>
<li>1.阻塞IO</li>
</ul>
<figure data-type="image" tabindex="1"><img src="https://sparkfengbo.github.io/post-images/1602498833576.jpg" alt="" loading="lazy"></figure>
<p>标红的这部分过程就是阻塞，直到阻塞结束recvfrom才能返回。</p>
<ul>
<li>2.非阻塞IO</li>
</ul>
<figure data-type="image" tabindex="2"><img src="https://sparkfengbo.github.io/post-images/1602498843741.jpg" alt="" loading="lazy"></figure>
<p>可以看出recvfrom总是立即返回。</p>
<ul>
<li>3.IO多路复用</li>
</ul>
<figure data-type="image" tabindex="3"><img src="https://sparkfengbo.github.io/post-images/1602498851907.jpg" alt="" loading="lazy"></figure>
<ul>
<li>4.信号驱动异步I/O模型</li>
</ul>
<figure data-type="image" tabindex="4"><img src="https://sparkfengbo.github.io/post-images/1602498859440.jpg" alt="" loading="lazy"></figure>
<ul>
<li>5.异步IO</li>
</ul>
<figure data-type="image" tabindex="5"><img src="https://sparkfengbo.github.io/post-images/1602498867473.jpg" alt="" loading="lazy"></figure>
<ul>
<li>五种模型对比</li>
</ul>
<figure data-type="image" tabindex="6"><img src="https://sparkfengbo.github.io/post-images/1602498874255.jpeg" alt="" loading="lazy"></figure>
<blockquote>
<p>同步非阻塞方式相比同步阻塞方式：<br>
优点是能够在等待任务完成的时间里干其他活了（包括提交其他任务，也就是 “后台” 可以有多个任务在同时执行）。<br>
缺点是任务完成的响应延迟增大了，因为每过一段时间才去轮询一次，而任务可能在两次轮询之间的任意时间完成。<br>
由于同步非阻塞方式需要不断轮询，而 “后台” 可能有多个任务在同时进行，人们就想到了循环查询多个任务的完成状态，只要有任何一个任务完成，就去处理它。这就是所谓的 “I/O 多路复用”。UNIX/Linux 下的 select、poll、epoll 就是干这个的（epoll 比 poll、select 效率高，做的事情是一样的）。Windows 下则有 WaitForMultipleObjects 和 IO Completion Ports API 与之对应（Windows API 的命名简直甩 POSIX API 几条街有木有！）</p>
</blockquote>
<h1 id="io多路复用">IO多路复用</h1>
<blockquote>
<p>目前支持I/O复用的系统调用有<strong>select、pselect、poll、epoll</strong>，下面几小结分别来学习一下select和epoll的使用。<br>
Linux 2.6之前是select、poll，2.6之后是epoll，Windows是IOCP。</p>
</blockquote>
<p>其实，epoll与select原理类似，只不过，epoll作出了一些重大改进，即：</p>
<ul>
<li>1.支持一个进程打开大数目的socket描述符(FD)</li>
</ul>
<blockquote>
<p>select 最不能忍受的是一个进程所打开的FD是有一定限制的，由FD_SETSIZE设置，默认值是2048。对于那些需要支持的上万连接数目的IM服务器来说显然太少了。这时候你一是可以选择修改这个宏然后重新编译内核，不过资料也同时指出这样会带来网络效率的下降，二是可以选择多进程的解决方案(传统的 Apache方案)，不过虽然linux上面创建进程的代价比较小，但仍旧是不可忽视的，加上进程间数据同步远比不上线程间同步的高效，所以也不是一种完美的方案。不过 epoll则没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。</p>
</blockquote>
<ul>
<li>2.IO效率不随FD数目增加而线性下降</li>
</ul>
<blockquote>
<p>传统的select/poll另一个致命弱点就是当你拥有一个很大的socket集合，不过由于网络延时，任一时间只有部分的socket是&quot;活跃&quot;的，但是select/poll每次调用都会线性扫描全部的集合，导致效率呈现线性下降。但是epoll不存在这个问题，它只会对&quot;活跃&quot;的socket进行操作---这是因为在内核实现中epoll是根据每个fd上面的callback函数实现的。那么，只有&quot;活跃&quot;的socket才会主动的去调用 callback函数，其他idle状态socket则不会，在这点上，epoll实现了一个&quot;伪&quot;AIO，因为这时候推动力在os内核。在一些 benchmark中，如果所有的socket基本上都是活跃的---比如一个高速LAN环境，epoll并不比select/poll有什么效率，相反，如果过多使用epoll_ctl,效率相比还有稍微的下降。但是一旦使用idle connections模拟WAN环境,epoll的效率就远在select/poll之上了。</p>
</blockquote>
<ul>
<li>3.使用mmap加速内核与用户空间的消息传递。</li>
</ul>
<blockquote>
<p>这点实际上涉及到epoll的具体实现了。无论是select,poll还是epoll都需要内核把FD消息通知给用户空间，如何避免不必要的内存拷贝就很重要，在这点上，epoll是通过内核于用户空间mmap同一块内存实现的。</p>
</blockquote>
<ul>
<li>4.内核微调</li>
</ul>
<blockquote>
<p>这一点其实不算epoll的优点了，而是整个linux平台的优点。也许你可以怀疑linux平台，但是你无法回避linux平台赋予你微调内核的能力。比如，内核TCP/IP协议栈使用内存池管理sk_buff结构，那么可以在运行时期动态调整这个内存pool(skb_head_pool)的大小 --- 通过echo XXXX&gt;/proc/sys/net/core/hot_list_length完成。再比如listen函数的第2个参数(TCP完成3次握手的数据包队列长度)，也可以根据你平台内存大小动态调整。更甚至在一个数据包面数目巨大但同时每个数据包本身大小却很小的特殊系统上尝试最新的NAPI网卡驱动架构。</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linux 硬链接软链接]]></title>
        <id>https://sparkfengbo.github.io/post/czxt-linux-ying-lian-jie-ruan-lian-jie/</id>
        <link href="https://sparkfengbo.github.io/post/czxt-linux-ying-lian-jie-ruan-lian-jie/">
        </link>
        <updated>2020-10-12T10:32:12.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li><a href="https://www.toutiao.com/i6753065098199171587/?tt_from=weixin&amp;utm_campaign=client_share&amp;wxshare_count=1&amp;timestamp=1584238470&amp;app=news_article&amp;utm_source=weixin&amp;utm_medium=toutiao_ios&amp;req_id=2020031510142901001404707528B359F1&amp;group_id=6753065098199171587">面试 | Linux 下软链接和硬链接的区别</a></li>
</ul>
<h1 id="硬链接">硬链接</h1>
<figure data-type="image" tabindex="1"><img src="https://sparkfengbo.github.io/post-images/1602498757010.png" alt="" loading="lazy"></figure>
<p>硬链接，inode节点指向的是同一个文件块<br>
<img src="https://sparkfengbo.github.io/post-images/1602498766032.jpeg" alt="" loading="lazy"></p>
<p>硬链接的作用是允许一个文件拥有多个有效路径名，这样用户就可以建立硬链接到重要文件,以防止“误删”的功能，由于对应该目录的索引节点有一个以上的连接，假设我们删除了原始的 foo.txt 文件：<br>
<img src="https://sparkfengbo.github.io/post-images/1602498773307.jpeg" alt="" loading="lazy"></p>
<p>此时文件的内容依然存在，所以只删除一个连接并不影响索引节点本身和其它的连接，只有当最后一个链接被删除后，文件的数据块及目录的连接才会被释放，也就是说，文件才会被真正删除。</p>
<h1 id="软链接">软链接</h1>
<figure data-type="image" tabindex="2"><img src="https://sparkfengbo.github.io/post-images/1602498779655.jpeg" alt="" loading="lazy"></figure>
<p>软链接又叫符号链接，这个文件包含了另一个文件的路径名，例如在上图中，foo.txt 就是 bar.txt 的软连接，bar.txt 是实际的文件，foo.txt 包含的是对于 bar.txt 的 inode 的记录。</p>
<p>软连接可以是任意文件或目录，可以链接不同文件系统的文件，在对符号文件进行读或写操作的时候，系统会自动把该操作转换为对源文件的操作，但删除链接文件时，系统仅仅删除链接文件，而不删除源文件本身，这一点类似于 Windows 操作系统下的快捷方式。<br>
<img src="https://sparkfengbo.github.io/post-images/1602498790074.jpeg" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linux 信号]]></title>
        <id>https://sparkfengbo.github.io/post/czxt-linux-xin-hao/</id>
        <link href="https://sparkfengbo.github.io/post/czxt-linux-xin-hao/">
        </link>
        <updated>2020-10-12T10:31:50.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li><a href="https://blog.csdn.net/colzer/article/details/8135542">linux基础编程：进程通信之信号</a></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linux 静态链接和动态链接]]></title>
        <id>https://sparkfengbo.github.io/post/czxt-linux-jing-tai-lian-jie-he-dong-tai-lian-jie/</id>
        <link href="https://sparkfengbo.github.io/post/czxt-linux-jing-tai-lian-jie-he-dong-tai-lian-jie/">
        </link>
        <updated>2020-10-12T10:30:43.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li><a href="https://www.toutiao.com/i6792927363316318723/?group_id=6792927363316318723">C程序的编译过程</a></li>
<li><a href="https://www.toutiao.com/i6793307776551485959/?tt_from=weixin&amp;utm_campaign=client_share&amp;wxshare_count=1&amp;timestamp=1584501857&amp;app=news_article&amp;utm_source=weixin&amp;utm_medium=toutiao_ios&amp;req_id=2020031811241601001404707704B74596&amp;group_id=6793307776551485959">静态链接与动态链接</a></li>
</ul>
<h1 id="c程序编译过程">C程序编译过程</h1>
<figure data-type="image" tabindex="1"><img src="https://sparkfengbo.github.io/post-images/1602498662494.jpeg" alt="" loading="lazy"></figure>
<h2 id="1预处理preprpcessing">1.预处理（Preprpcessing）</h2>
<p><strong>使用预处理器把源文件test.c经过预处理生成test.i文件，预处理用于将所有的#include头文件以及宏定义替换成其真正的内容。</strong></p>
<pre><code>gcc -E test.c -o test.i
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://sparkfengbo.github.io/post-images/1602498670125.png" alt="" loading="lazy"></figure>
<h2 id="2编译compilation">2.编译（Compilation）</h2>
<p><strong>使用编译器将预处理文件test.i编译成汇编文件test.s。</strong></p>
<pre><code>gcc -S test.i -o test.s
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://sparkfengbo.github.io/post-images/1602498677324.png" alt="" loading="lazy"></figure>
<h2 id="3汇编assemble">3.汇编（Assemble）</h2>
<p><strong>使用汇编器将汇编文件test.s转换成目标文件test.o。</strong></p>
<pre><code>gcc -c test.s -o test.o
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://sparkfengbo.github.io/post-images/1602498684007.png" alt="" loading="lazy"></figure>
<h2 id="4链接linking">4.链接（Linking）</h2>
<p><strong>链接过程使用链接器将该目标文件与其他目标文件、库文件、启动文件等链接起来生成可执行文件。</strong></p>
<pre><code>gcc test.o -o test.exe
</code></pre>
<hr>
<h1 id="静态-动态链接">静态、动态链接？</h1>
<ul>
<li>1、什么是静态链接？</li>
</ul>
<p>静态链接是由链接器在链接时将库的内容加入到可执行程序中的做法。链接器是一个独立程序，将一个或多个库或目标文件（先前由编译器或汇编器生成）链接到一块生成可执行程序。这里的库指的是静态链接库，Windows下以.lib为后缀，Linux下以.a为后缀。</p>
<ul>
<li>2、什么是动态链接？</li>
</ul>
<p>动态链接（Dynamic Linking），把链接这个过程推迟到了运行时再进行，在可执行文件装载时或运行时，由操作系统的装载程序加载库。这里的库指的是动态链接库，Windows下以.dll为后缀，Linux下以.so为后缀。值得一提的是，在Windows下的动态链接也可以用到.lib为后缀的文件，但这里的.lib文件叫做导入库，是由.dll文件生成的。</p>
<h2 id="实验">实验</h2>
<p>文件1（main.c）：</p>
<pre><code>#include &quot;test.h&quot;

int main(void)
{
    print_hello();
    system(&quot;pause&quot;);
    return 0;
}
</code></pre>
<p>文件2（test.c）：</p>
<pre><code>#include &quot;test.h&quot;

void print_hello(void)
{
    printf(&quot;hello world\n&quot;);
}
</code></pre>
<p>文件3（test.h）：</p>
<pre><code>#ifndef __TEST_H
#define __TEST_H

#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

void print_hello(void);

#endif
</code></pre>
<h3 id="静态链接实验">静态链接实验</h3>
<ul>
<li>
<p>编译</p>
<pre><code>gcc -c test.c main.c
</code></pre>
<p>多出了test.o和main.o文件</p>
</li>
<li>
<p>静态链接库<br>
接下来使用ar工具把test.o和main.o打包成一个静态库文件lib_test.lib</p>
<pre><code>ar rv lib_test.lib test.o main.o
</code></pre>
</li>
<li>
<p>链接<br>
把这个静态库链接成可执行文件lib_test.exe</p>
<pre><code>gcc lib_test.lib -o lib_test.exe
</code></pre>
</li>
</ul>
<p>可以直接执行lib_test.exe</p>
<h3 id="动态链接实验">动态链接实验</h3>
<ul>
<li>
<p>动态链接库</p>
<pre><code>gcc test.c -shared -o dll_test.dll 
</code></pre>
<pre><code>  多出了动态库文件dll_test.dll
</code></pre>
</li>
<li>
<p>生成可执行文件<br>
用该动态库文件dll_test.dll与main.c一起编译生成可执行文件dll_test.exe</p>
<pre><code>gcc dll_test.dll main.c -o dll_test.exe
</code></pre>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Linux 管道]]></title>
        <id>https://sparkfengbo.github.io/post/czxt-linux-guan-dao/</id>
        <link href="https://sparkfengbo.github.io/post/czxt-linux-guan-dao/">
        </link>
        <updated>2020-10-12T10:30:17.000Z</updated>
        <content type="html"><![CDATA[<ul>
<li><a href="https://oilbeater.com/linux/2012/05/29/linux_pipe.html">linux管道机制简介</a></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[6.安全]]></title>
        <id>https://sparkfengbo.github.io/post/czxt-6an-quan/</id>
        <link href="https://sparkfengbo.github.io/post/czxt-6an-quan/">
        </link>
        <updated>2020-10-12T10:29:46.000Z</updated>
        <content type="html"><![CDATA[<p>这一部分的内容和HTTPS重合</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[5.1.mmap内存映射]]></title>
        <id>https://sparkfengbo.github.io/post/czxt-51mmap-nei-cun-ying-she/</id>
        <link href="https://sparkfengbo.github.io/post/czxt-51mmap-nei-cun-ying-she/">
        </link>
        <updated>2020-10-12T10:28:54.000Z</updated>
    </entry>
    <entry>
        <title type="html"><![CDATA[5.0输入输出和IO(包含零拷贝)]]></title>
        <id>https://sparkfengbo.github.io/post/czxt-50-shu-ru-shu-chu-he-iobao-han-ling-kao-bei/</id>
        <link href="https://sparkfengbo.github.io/post/czxt-50-shu-ru-shu-chu-he-iobao-han-ling-kao-bei/">
        </link>
        <updated>2020-10-12T10:26:00.000Z</updated>
        <content type="html"><![CDATA[<p>[TOC]</p>
<h1 id="1io硬件">1.IO硬件</h1>
<h2 id="分类">分类</h2>
<ul>
<li>块设备 block device
<ul>
<li>块设备把信息存储在固定大小的块中，每个块有自己的地址</li>
<li>CR-ROM、USB</li>
</ul>
</li>
<li>字符设备 character device
<ul>
<li>字符设备以字符为单位发送或接收一个字符流，而不考虑任何块结构。字符设备是不可寻址的，也没有任何寻道操作。</li>
<li>打印机</li>
<li>网络接口</li>
<li>鼠标（用作指点设备）</li>
<li>以及大多数与磁盘不同的设备都可看作是字符设备。</li>
</ul>
</li>
</ul>
<h2 id="设备控制器">设备控制器</h2>
<h2 id="内存映射io">内存映射IO</h2>
<p>优点：</p>
<ul>
<li>对于内存映射I/O，I/O设备驱动程序可以完全用C语言编写。如果不使用内存映射I/O，就要用到某些汇编代码。</li>
<li>不需要特殊的保护机制来阻止用户进程执行I/O操作</li>
<li>可以引用内存的每一条指令也可以引用控制寄存器。</li>
</ul>
<hr>
<h1 id="2io软件">2.IO软件</h1>
<h2 id="程序控制io">程序控制IO</h2>
<p>CPU要不断地查询设备以了解它是否就绪准备接收另一个字符。这一行为经常称为轮询（polling）或忙等待（busy waiting）。</p>
<p>十分简单但是有缺点，即直到全部I/O完成之前要占用CPU的全部时间。</p>
<h2 id="中断驱动io">中断驱动IO</h2>
<figure data-type="image" tabindex="1"><img src="https://sparkfengbo.github.io/post-images/1602498378648.png" alt="" loading="lazy"></figure>
<p>中断驱动I/O的一个明显缺点是中断发生在每个字符上。中断要花费时间，所以这一方法将浪费一定数量的CPU时间。</p>
<h2 id="中断io">中断IO</h2>
<figure data-type="image" tabindex="2"><img src="https://sparkfengbo.github.io/post-images/1602498388360.png" alt="" loading="lazy"></figure>
<ul>
<li>用户进程向 CPU 发起 read 系统调用读取数据，由用户态切换为内核态，然后一直阻塞等待数据的返回。</li>
<li>CPU 在接收到指令以后对磁盘发起 I/O 请求，将磁盘数据先放入磁盘控制器缓冲区。<br>
数据准备完成以后，磁盘向 CPU 发起 I/O 中断。</li>
<li>CPU 收到 I/O 中断以后将磁盘缓冲区中的数据拷贝到内核缓冲区，然后再从内核缓冲区拷贝到用户缓冲区。</li>
<li>用户进程由内核态切换回用户态，解除阻塞状态，然后等待 CPU 的下一个执行时间钟。</li>
</ul>
<p><strong>2次上下文切换、2次拷贝</strong></p>
<h2 id="使用dma的io">使用DMA的IO</h2>
<p>DMA重大的成功是将中断的次数从打印每个字符一次减少到打印每个缓冲区一次。如果有许多字符并且中断十分缓慢，那么采用DMA可能是重要的改进。另一方面，DMA控制器通常比主CPU要慢很多。如果DMA控制器不能以全速驱动设备，或者CPU在等待DMA中断的同时没有其他事情要做，那么采用中断驱动I/O甚至采用程序控制I/O也许更好。</p>
<h2 id="直接存储器存取-dma">直接存储器存取 DMA</h2>
<p>Direct Memory Access，直接内存存取</p>
<p>无论DMA控制器在物理上处于什么地方，它都能够独立于CPU而访问系统总线</p>
<figure data-type="image" tabindex="3"><img src="https://sparkfengbo.github.io/post-images/1602498401543.png" alt="" loading="lazy"></figure>
<p>工作原理：</p>
<ul>
<li>没有DMA</li>
</ul>
<blockquote>
<p>“我们首先看一下没有使用DMA时磁盘如何读。首先，控制器从磁盘驱动器串行地、一位一位地读一个块（一个或多个扇区），直到将整块信息放入控制器的内部缓冲区中。接着，它计算校验和，以保证没有读错误发生。然后控制器产生一个中断。当操作系统开始运行时，它重复地从控制器的缓冲区中一次一个字节或一个字地读取该块的信息，并将其存入内存中。”</p>
</blockquote>
<ul>
<li>有DMA</li>
</ul>
<blockquote>
<p>首先，CPU通过设置DMA控制器的寄存器对它进行编程，所以DMA控制器知道将什么数据传送到什么地方（图5-4中的第1步）。DMA控制器还要向磁盘控制器发出一个命令，通知它从磁盘读数据到其内部的缓冲区中，并且对校验和进行检验。如果磁盘控制器的缓冲区中的数据是有效的，那么DMA就可以开始了。</p>
<p>DMA控制器通过在总线上发出一个读请求到磁盘控制器而发起DMA传送（第2步）。这一读请求看起来与任何其他读请求是一样的，并且磁盘控制器并不知道或者并不关心它是来自CPU还是来自DMA控制器。一般情况下，要写的内存地址在总线的地址线上，所以当磁盘控制器从其内部缓冲区中读取下一个字的时候，它知道将该字写到什么地方。写到内存是另一个标准总线周期（第3步）。当写操作完成时，磁盘控制器在总线上发出一个应答信号到DMA控制器（第4步）。于是，DMA控制器步增要使用的内存地址，并且步减字节计数。如果字节计数仍然大于0，则重复第2步到第4步，直到字节计数到达0。此时，DMA控制器将中断CPU以便让CPU知道传送现在已经完成了。当操作系统开始工作时，用不着将磁盘块复制到内存中，因为它已经在内存中了。</p>
</blockquote>
<blockquote>
<p>普通中断方式是在数据缓冲寄存器满后，发中断请求，CPU进行中断处理<br>
DMA方式则是以数据块为单位传输的,在所要求传送的数据块全部传送结束时要求CPU进行中断处理,大大减少了CPU进行中断处理的次数<br>
总结:DMA方式不需CPU干预传送操作,仅仅是开始和结尾借用CPU一点时间,其余不占用CPU任何资源，中断方式是程序切换,每次操作需要保护和恢复现场</p>
<p>中断控制方式虽然在某种程度上解决了上述问题，但由于中断次数多，因而CPU仍需要花较多的时间处理中断，而且能够并行操作的设备台数也受到中断处理时间的限制，中断次数增多导致数据丢失。</p>
<p>DMA方式和通道方式较好地解决了上述问题。这两种方式采用了外设和内存直接交换数据的方式。只有在一段数据传送结束时，这两种方式才发出中断信号要求CPU做善后处理，从而大大减少了CPU的工作负担。中断控制方式虽然在某种程度上解决了上述问题，但由于中断次数多，因而CPU仍需要花较多的时间处理中断，而且能够并行操作的设备台数也受到中断处理时间的限制，中断次数增多导致数据丢失。DMA方式和通道方式较好地解决了上述问题。这两种方式采用了外设和内存直接交换数据的方式。只有在一段数据传送结束时，这两种方式才发出中断信号要求CPU做善后处理，从而大大减少了CPU的工作负担。</p>
</blockquote>
<p>参考文章</p>
<ul>
<li><a href="https://byte.baike.com/cwiki/DMA&amp;fr=toutiao?isPreloadWebView=1">DMA-字节百科</a></li>
</ul>
<blockquote>
<p>DMA 传输将数据从一个地址空间复制到另外一个地址空间。当CPU 初始化这个传输动作，传输动作本身是由 DMA 控制器来实行和完成。典型的例子就是移动一个外部内存的区块到芯片内部更快的内存区。像是这样的操作并没有让处理器工作拖延，反而可以被重新排程去处理其他的工作。DMA 传输对于高效能 嵌入式系统算法和网络是很重要的。</p>
<p>在实现DMA传输时，是由DMA控制器直接掌管总线，因此，存在着一个总线控制权转移问题。即DMA传输前，CPU要把总线控制权交给DMA控制器，而在结束DMA传输后，DMA控制器应立即把总线控制权再交回给CPU。一个完整的DMA传输过程必须经过DMA请求、DMA响应、DMA传输、DMA结束4个步骤。</p>
<ul>
<li>请求
<ul>
<li>CPU对DMA控制器初始化，并向I/O接口发出操作命令，I/O接口提出DMA请求。</li>
</ul>
</li>
<li>响应
<ul>
<li>DMA控制器对DMA请求判别优先级及屏蔽，向总线裁决逻辑提出总线请求。当CPU执行完当前总线周期即可释放总线控制权。此时，总线裁决逻辑输出总线应答，表示DMA已经响应，通过DMA控制器通知I/O接口开始DMA传输。</li>
</ul>
</li>
<li>传输
<ul>
<li>DMA控制器获得总线控制权后，CPU即刻挂起或只执行内部操作，由DMA控制器输出读写命令，直接控制RAM与I/O接口进行DMA传输。</li>
<li>在DMA控制器的控制下，在存储器和外部设备之间直接进行数据传送，在传送过程中不需要中央处理器的参与。开始时需提供要传送的数据的起始位置和数据长度。</li>
</ul>
</li>
<li>结束
<ul>
<li>当完成规定的成批数据传送后，DMA控制器即释放总线控制权，并向I/O接口发出结束信号。当I/O接口收到结束信号后，一方面停 止I/O设备的工作，另一方面向CPU提出中断请求，使CPU从不介入的状态解脱，并执行一段检查本次DMA传输操作正确性的代码。最后，带着本次操作结果及状态继续执行原来的程序。</li>
</ul>
</li>
</ul>
<p>由此可见，DMA传输方式无需CPU直接控制传输，也没有中断处理方式那样保留现场和恢复现场的过程，通过硬件为RAM与I/O设备开辟一条直接传送数据的通路，使CPU的效率大为提高。</p>
<p>DMA控制器与CPU怎样分时使用内存呢?通常采用以下三种方法：(1)停止CPU访内存；(2)周期挪用；(3)DMA与CPU交替访问内存。</p>
</blockquote>
<figure data-type="image" tabindex="4"><img src="https://sparkfengbo.github.io/post-images/1602498415009.png" alt="" loading="lazy"></figure>
<ul>
<li>用户进程向 CPU 发起 read 系统调用读取数据，由用户态切换为内核态，然后一直阻塞等待数据的返回。</li>
<li>CPU 在接收到指令以后对 DMA 磁盘控制器发起调度指令。</li>
<li>DMA 磁盘控制器对磁盘发起 I/O 请求，将磁盘数据先放入磁盘控制器缓冲区，CPU 全程不参与此过程。</li>
<li>数据读取完成后，DMA 磁盘控制器会接受到磁盘的通知，将数据从磁盘控制器缓冲区拷贝到内核缓冲区。</li>
<li>DMA 磁盘控制器向 CPU 发出数据读完的信号，由 CPU 负责将数据从内核缓冲区拷贝到用户缓冲区。</li>
<li>用户进程由内核态切换回用户态，解除阻塞状态，然后等待 CPU 的下一个执行时间钟。</li>
</ul>
<p><strong>2次上下文切换，2次拷贝</strong></p>
<h2 id="零拷贝">零拷贝</h2>
<ul>
<li><a href="https://www.toutiao.com/i6802161744752935436/?tt_from=weixin&amp;utm_campaign=client_share&amp;wxshare_count=1&amp;timestamp=1583802979&amp;app=news_article&amp;utm_source=weixin&amp;utm_medium=toutiao_android&amp;req_id=202003100916180100260771961F64434A&amp;group_id=6802161744752935436">深入剖析神秘的“零拷贝”「转」</a></li>
<li>强烈推荐这篇文章 <a href="https://juejin.im/post/5d84bd1f6fb9a06b2d780df7">深入剖析Linux IO原理和几种零拷贝机制的实现</a></li>
</ul>
<h3 id="传统io">传统IO</h3>
<h4 id="1传统读写">1.传统读写</h4>
<pre><code>read(file_fd, tmp_buf, len);
write(socket_fd, tmp_buf, len);
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://sparkfengbo.github.io/post-images/1602498425858.png" alt="" loading="lazy"></figure>
<p><strong>整个过程涉及 2 次 CPU 拷贝、2 次 DMA 拷贝总共 4 次拷贝，以及 4 次上下文切换</strong></p>
<ul>
<li>上下文切换：当用户程序向内核发起系统调用时，CPU 将用户进程从用户态切换到内核态；当系统调用返回时，CPU 将用户进程从内核态切换回用户态。</li>
<li>CPU拷贝：由 CPU 直接处理数据的传送，数据拷贝时会一直占用 CPU 的资源。</li>
<li>DMA拷贝：由 CPU 向DMA磁盘控制器下达指令，让 DMA 控制器来处理数据的传送，数据传送完毕再把信息反馈给 CPU，从而减轻了 CPU 资源的占有率。</li>
</ul>
<h4 id="2传统读">2.传统读</h4>
<pre><code>read(file_fd, tmp_buf, len);
</code></pre>
<p><strong>2 次上下文切换，1 次 DMA 拷贝和 1 次 CPU 拷贝</strong></p>
<ul>
<li>用户进程通过 read() 函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space）。</li>
<li>CPU利用DMA控制器将数据从主存或硬盘拷贝到内核空间（kernel space）的读缓冲区（read buffer）。</li>
<li>CPU将读缓冲区（read buffer）中的数据拷贝到用户空间（user space）的用户缓冲区（user buffer）。</li>
<li>上下文从内核态（kernel space）切换回用户态（user space），read 调用执行返回。</li>
</ul>
<h4 id="3传统写">3.传统写</h4>
<pre><code>write(socket_fd, tmp_buf, len);
</code></pre>
<p><strong>2 次上下文切换，1 次 CPU 拷贝和 1 次 DMA 拷贝</strong></p>
<ul>
<li>户进程通过 write() 函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space）。</li>
<li>CPU 将用户缓冲区（user buffer）中的数据拷贝到内核空间（kernel space）的网络缓冲区（socket buffer）。</li>
<li>CPU 利用 DMA 控制器将数据从网络缓冲区（socket buffer）拷贝到网卡进行数据传输。</li>
<li>上下文从内核态（kernel space）切换回用户态（user space），write 系统调用执行返回。</li>
</ul>
<h3 id="零拷贝-2">零拷贝</h3>
<p>在 Linux 中零拷贝技术主要有 3 个实现思路：用户态直接 I/O、减少数据拷贝次数以及写时复制技术。</p>
<ul>
<li>用户态直接 I/O：应用程序可以直接访问硬件存储，操作系统内核只是辅助数据传输。这种方式依旧存在用户空间和内核空间的上下文切换，硬件上的数据直接拷贝至了用户空间，不经过内核空间。因此，直接 I/O 不存在内核空间缓冲区和用户空间缓冲区之间的数据拷贝。</li>
<li>减少数据拷贝次数：在数据传输过程中，避免数据在用户空间缓冲区和系统内核空间缓冲区之间的CPU拷贝，以及数据在系统内核空间内的CPU拷贝，这也是当前主流零拷贝技术的实现思路。</li>
<li>写时复制技术：写时复制指的是当多个进程共享同一块数据时，如果其中一个进程需要对这份数据进行修改，那么将其拷贝到自己的进程地址空间中，如果只是数据读取操作则不需要进行拷贝操作。</li>
</ul>
<h4 id="用户态直接-io">用户态直接 I/O</h4>
<figure data-type="image" tabindex="6"><img src="https://sparkfengbo.github.io/post-images/1602498439992.png" alt="" loading="lazy"></figure>
<blockquote>
<p>用户态直接 I/O 只能适用于不需要内核缓冲区处理的应用程序，这些应用程序通常在进程地址空间有自己的数据缓存机制，称为自缓存应用程序，如数据库管理系统就是一个代表。其次，这种零拷贝机制会直接操作磁盘 I/O，由于 CPU 和磁盘 I/O 之间的执行时间差距，会造成大量资源的浪费，解决方案是配合异步 I/O 使用。</p>
</blockquote>
<h4 id="mmap-write">mmap + write</h4>
<p><strong>减少了 1 次 CPU 拷贝操作</strong></p>
<p><img src="https://sparkfengbo.github.io/post-images/1602498449207.png" alt="" loading="lazy"><br>
<img src="https://sparkfengbo.github.io/post-images/1602498455475.png" alt="" loading="lazy"></p>
<h4 id="sendfile">sendfile</h4>
<p><strong>sendfile 系统调用在 Linux 内核版本 2.1 中被引入，目的是简化通过网络在两个通道之间进行的数据传输过程。sendfile 系统调用的引入，不仅减少了 CPU 拷贝的次数，还减少了上下文切换的次数</strong></p>
<p><img src="https://sparkfengbo.github.io/post-images/1602498461791.png" alt="" loading="lazy"><br>
<img src="https://sparkfengbo.github.io/post-images/1602498466238.png" alt="" loading="lazy"></p>
<h4 id="sendfile-dma-gather-copy">sendfile + DMA gather copy</h4>
<p><strong>Linux 2.4 版本的内核对 sendfile 系统调用进行修改，为  DMA 拷贝引入了 gather 操作。它将内核空间（kernel space）的读缓冲区（read buffer）中对应的数据描述信息（内存地址、地址偏移量）记录到相应的网络缓冲区（ socket  buffer）中，由 DMA 根据内存地址、地址偏移量将数据批量地从读缓冲区（read buffer）拷贝到网卡设备中，这样就省去了内核空间中仅剩的 1 次 CPU 拷贝操作s</strong></p>
<p><img src="https://sparkfengbo.github.io/post-images/1602498477091.png" alt="" loading="lazy"><br>
<img src="https://sparkfengbo.github.io/post-images/1602498482857.png" alt="" loading="lazy"></p>
<h4 id="splice">splice</h4>
<p><strong>sendfile 只适用于将数据从文件拷贝到 socket 套接字上，同时需要硬件的支持，这也限定了它的使用范围。Linux 在 2.6.17 版本引入 splice 系统调用，不仅不需要硬件支持，还实现了两个文件描述符之间的数据零拷贝。</strong></p>
<pre><code>splice(fd_in, off_in, fd_out, off_out, len, flags);
</code></pre>
<p><img src="https://sparkfengbo.github.io/post-images/1602498489058.png" alt="" loading="lazy"><br>
<img src="https://sparkfengbo.github.io/post-images/1602498497440.png" alt="" loading="lazy"></p>
<h4 id="写时复制">写时复制</h4>
<blockquote>
<p>在某些情况下，内核缓冲区可能被多个进程所共享，如果某个进程想要这个共享区进行 write 操作，由于 write 不提供任何的锁操作，那么就会对共享区中的数据造成破坏，写时复制的引入就是 Linux 用来保护数据的。<br>
写时复制指的是当多个进程共享同一块数据时，如果其中一个进程需要对这份数据进行修改，那么就需要将其拷贝到自己的进程地址空间中。这样做并不影响其他进程对这块数据的操作，每个进程要修改的时候才会进行拷贝，所以叫写时拷贝。这种方法在某种程度上能够降低系统开销，如果某个进程永远不会对所访问的数据进行更改，那么也就永远不需要拷贝。</p>
</blockquote>
<h4 id="linux零拷贝对比">Linux零拷贝对比</h4>
<figure data-type="image" tabindex="7"><img src="https://sparkfengbo.github.io/post-images/1602498504843.png" alt="" loading="lazy"></figure>
<hr>
<h1 id="3io软件层级">3.IO软件层级</h1>
<h1 id="4盘">4.盘</h1>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[4.存储和文件]]></title>
        <id>https://sparkfengbo.github.io/post/czxt-4cun-chu-he-wen-jian/</id>
        <link href="https://sparkfengbo.github.io/post/czxt-4cun-chu-he-wen-jian/">
        </link>
        <updated>2020-10-12T10:23:50.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1文件">1.文件</h1>
<h2 id="文件命名"><s>文件命名</s></h2>
<h2 id="文件结构"><s>文件结构</s></h2>
<h2 id="文件类型">文件类型</h2>
<ul>
<li>
<p>普通文件</p>
<ul>
<li>普通文件一般分为ASCII文件和二进制文件。ASCII文件由多行正文组成。在某些系统中，每行用回车符结束，其他系统则用换行符结束。有些系统还同时采用回车符和换行符（如MS-DOS）。文件中各行的长度不一定相同。</li>
<li>ASCII文件的最大优势是可以显示和打印，还可以用任何文本编辑器进行编辑。</li>
<li>其他与ASCII文件不同的是二进制文件。打印出来的二进制文件是无法理解的、充满混乱字符的一张表。通常，二进制文件有一定的内部结构，使用该文件的程序才了解这种结构。</li>
</ul>
</li>
<li>
<p>目录</p>
</li>
<li>
<p>字符特殊文件</p>
<ul>
<li>和输入/输出有关，用于串行I/O类设备，如终端、打印机、网络等。</li>
</ul>
</li>
<li>
<p>块特殊文件</p>
<ul>
<li>用于磁盘类设备。</li>
</ul>
</li>
</ul>
<h2 id="文件读取">文件读取</h2>
<ul>
<li><s>顺序存取</s></li>
<li>随机存取</li>
</ul>
<h2 id="文件属性">文件属性</h2>
<blockquote>
<p>文件都有文件名和数据。另外，所有的操作系统还会保存其他与文件相关的信息，如文件创建的日期和时间、文件大小等。这些附加信息称为文件属性（attribute），有些人称之为元数据（metadata）。文件的属性在不同系统中差别很大。一些常用的属性在图4-4中列出，但还存在其他的属性。</p>
</blockquote>
<figure data-type="image" tabindex="1"><img src="https://sparkfengbo.github.io/post-images/1602498249545.png" alt="" loading="lazy"></figure>
<h1 id="2目录">2.目录</h1>
<h2 id="结构">结构</h2>
<ul>
<li>一级目录系统</li>
<li>层次目录系统</li>
</ul>
<figure data-type="image" tabindex="2"><img src="https://sparkfengbo.github.io/post-images/1602498258561.png" alt="" loading="lazy"></figure>
<h2 id="路径名">路径名</h2>
<figure data-type="image" tabindex="3"><img src="https://sparkfengbo.github.io/post-images/1602498267327.png" alt="" loading="lazy"></figure>
<h1 id="3文件系统的实现">3.文件系统的实现</h1>
<h2 id="文件系统布局">文件系统布局</h2>
<figure data-type="image" tabindex="4"><img src="https://sparkfengbo.github.io/post-images/1602498275229.png" alt="" loading="lazy"></figure>
<blockquote>
<p>多数磁盘划分为一个或多个分区，每个分区中有一个独立的文件系统。磁盘的0号扇区称为主引导记录（Master Boot Record，MBR），用来引导计算机。在MBR的结尾是分区表。该表给出了每个分区的起始和结束地址。表中的一个分区被标记为活动分区。</p>
</blockquote>
<blockquote>
<p>在计算机被引导时，BIOS读入并执行MBR。MBR做的第一件事是确定活动分区，读入它的第一个块，称为引导块（boot block），并执行之。引导块中的程序将装载该分区中的操作系统。为统一起见，每个分区都从一个启动块开始，即使它不含有一个可启动的操作系统。</p>
</blockquote>
<h2 id="文件的实现">文件的实现</h2>
<ul>
<li>连续分配
<ul>
<li>把每个文件作为一连串连续数据块存储在磁盘上</li>
<li>实现简单，记录第一块的磁盘地址和文件的块数即可</li>
<li>读操作更好</li>
<li>缺点： 磁盘碎片</li>
</ul>
</li>
</ul>
<figure data-type="image" tabindex="5"><img src="https://sparkfengbo.github.io/post-images/1602498286294.png" alt="" loading="lazy"></figure>
<ul>
<li>
<p>链表分配</p>
<ul>
<li>没有磁盘碎片</li>
</ul>
<blockquote>
<p>与连续分配方案不同，这一方法可以充分利用每个磁盘块。不会因为磁盘碎片（除了最后一块中的内部碎片）而浪费存储空间。同样，在目录项中，只需要存放第一块的磁盘地址，文件的其他块就可以从这个首块地址查找到。</p>
</blockquote>
<ul>
<li>随机存取缓慢，需要链表查找</li>
<li>指针占去了一些字节<br>
<img src="https://sparkfengbo.github.io/post-images/1602498300227.png" alt="" loading="lazy"></li>
</ul>
</li>
<li>
<p>在内存中采用表的链表分配</p>
<ul>
<li><strong>如果取出每个磁盘块的指针字，把它放在内存的一个表中，就可以解决上述链表的两个不足。</strong></li>
<li>内存中的这样一个表格称为<strong>文件分配表（File Allocation Table，FAT）</strong>。</li>
<li>保留所有磁盘块的链接表的表大小正比于磁盘自身的大小，磁盘越大，这个表可能很大。</li>
</ul>
</li>
</ul>
<figure data-type="image" tabindex="6"><img src="https://sparkfengbo.github.io/post-images/1602498310160.png" alt="" loading="lazy"></figure>
<ul>
<li>i节点
<ul>
<li>给每个文件赋予一个称为i节点（index-node）的数据结构，其中列出了文件属性和文件块的磁盘地址。</li>
<li><strong>只有在对应文件打开时，其i节点才在内存中</strong></li>
<li>i节点机制需要在内存中有一个数组，其大小正比于可能要同时打开的最大文件个数。它与磁盘无关</li>
<li>相对于在内存中采用表的方式而言，这种机制具有很大的优势，即只有在对应文件打开时，其i节点才在内存中<br>
<img src="https://sparkfengbo.github.io/post-images/1602498320660.png" alt="" loading="lazy"></li>
</ul>
</li>
</ul>
<h2 id="目录的实现">目录的实现</h2>
<p>所有目录项大小一样的实现<br>
<img src="https://sparkfengbo.github.io/post-images/1602498329477.png" alt="" loading="lazy"></p>
<p>非-所有目录项大小一样的实现</p>
<p>“有三个文件，project-budget、personnel和foo”<br>
<img src="https://sparkfengbo.github.io/post-images/1602498337576.png" alt="" loading="lazy"></p>
<h2 id="实现">实现</h2>
<ul>
<li><a href="https://zh.wikipedia.org/wiki/NTFS">NTFS</a></li>
<li>FAT</li>
<li>EXT2
<ul>
<li>https://wizardforcel.gitbooks.io/vbird-linux-basic-4e/content/59.html</li>
</ul>
</li>
<li>HFS （苹果）</li>
</ul>
]]></content>
    </entry>
</feed>